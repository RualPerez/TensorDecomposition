{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Program to solve the MNIST classification problem using CPD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cuda is available:  True \n",
      "Use cuda:  True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch.nn.parameter import Parameter\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.nn.init as init\n",
    "from torch.utils import data\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "\n",
    "import math\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch.multiprocessing as mp\n",
    "\n",
    "# Use GPU if available\n",
    "use_cuda = torch.cuda.is_available()\n",
    "#use_cuda = False # Run on cpu even if cuda is available\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "print(\"Cuda is available: \",torch.cuda.is_available(),\"\\nUse cuda: \",use_cuda)\n",
    "\n",
    "# PCA of the training set\n",
    "perform_pca = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Loading MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To speed up training we'll only work on a subset of the data\n",
    "\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import check_random_state\n",
    "\n",
    "# Load data from https://www.openml.org/d/554\n",
    "X, y = fetch_openml('mnist_784', version=1, return_X_y=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performing PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if perform_pca:\n",
    "    from scipy.linalg import svd\n",
    "\n",
    "    X = X.astype('float32')\n",
    "    N, M = X.shape\n",
    "\n",
    "    # Std data\n",
    "    Y = X - np.ones((N,1))*X.mean(axis=0)\n",
    "    Y /= 255.\n",
    "    ## Y = Y[:,np.std(Y,0) != 0]\n",
    "    ## Y = Y*(1/np.std(Y,0))\n",
    "\n",
    "    # PCA\n",
    "    U,S,V = svd(Y,full_matrices=False)\n",
    "    rho = (S*S) / (S*S).sum()\n",
    "    Z = Y@V # matrix multiplication\n",
    "    Z = Z[:,:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create train, val & test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information on dataset\n",
      "x_train (1024, 15)\n",
      "targets_train (1024,)\n",
      "x_valid (512, 15)\n",
      "targets_valid (512,)\n",
      "x_test (512, 15)\n",
      "targets_test (512,)\n",
      "num_features:  15\n"
     ]
    }
   ],
   "source": [
    "# Specify the size of the training, cross validation and test set\n",
    "train_samples = 1024 #12800  #1024\n",
    "cv_samples    = 512 #1024 #512\n",
    "test_samples  = 512 #1024 #512\n",
    "\n",
    "y = y.astype('int32')\n",
    "\n",
    "if perform_pca:\n",
    "    ### Use output from PCA ###\n",
    "    random_state = check_random_state(0)\n",
    "    permutation = random_state.permutation(X.shape[0])\n",
    "    Z = Z[permutation]\n",
    "    y = y[permutation]\n",
    "    Z = Z.reshape((X.shape[0], -1))\n",
    "\n",
    "    x_train, X_test, targets_train, y_test = train_test_split(\n",
    "        Z, y, train_size=train_samples, test_size= (cv_samples+test_samples) )\n",
    "\n",
    "    x_valid, x_test, targets_valid, targets_test = train_test_split(\n",
    "        X_test, y_test, train_size=cv_samples, test_size=test_samples)\n",
    "else:\n",
    "    ### no PCA, use raw data ###\n",
    "    # Split in training, testing and validation set\n",
    "    x_train, X_test, targets_train, y_test = train_test_split(\n",
    "        X, y, train_size=train_samples, test_size=(cv_samples+test_samples))\n",
    "\n",
    "    x_valid, x_test, targets_valid, targets_test = train_test_split(\n",
    "        X_test, y_test, train_size=cv_samples, test_size=test_samples)\n",
    "\n",
    "num_features = x_train.shape[1]\n",
    "\n",
    "print(\"Information on dataset\")\n",
    "print(\"x_train\", x_train.shape)\n",
    "print(\"targets_train\", targets_train.shape)\n",
    "print(\"x_valid\", x_valid.shape)\n",
    "print(\"targets_valid\", targets_valid.shape)\n",
    "print(\"x_test\", x_test.shape)\n",
    "print(\"targets_test\", targets_test.shape)\n",
    "print('num_features: ',num_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank = 7 # Rank of the full decomposed tensor\n",
    "poly_order = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vandermonde vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def vandermonde_vec(dataset, num_instances, num_features):\n",
    "    u = np.zeros((num_instances,num_features,poly_order))\n",
    "    # u is a 3-dimensional tensor, which contains the Vandermonde vectors for every feature\n",
    "    # and every training point\n",
    "    \n",
    "    # Get powers\n",
    "    for i in range(num_instances):\n",
    "        for j in range(num_features):\n",
    "            for k in range(poly_order):\n",
    "                u[i,j,k] = np.power([dataset[i,j]], k)\n",
    "    \n",
    "    return u\n",
    "\n",
    "x_train = vandermonde_vec(x_train, x_train.shape[0], num_features)\n",
    "x_valid = vandermonde_vec(x_valid, x_valid.shape[0], num_features)\n",
    "x_test = vandermonde_vec(x_test, x_test.shape[0], num_features)\n",
    "\n",
    "x_train = torch.FloatTensor(x_train)\n",
    "x_valid = torch.FloatTensor(x_valid)\n",
    "x_test = torch.FloatTensor(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64 # used by the generators and given as input to net()\n",
    "# Parameters for the generator\n",
    "if use_cuda:\n",
    "    params = {'batch_size': batch_size,\n",
    "              'shuffle': True,\n",
    "              'num_workers': 8,\n",
    "              'drop_last': True,\n",
    "              'pin_memory': True}\n",
    "else:\n",
    "    params = {'batch_size': batch_size,\n",
    "              'shuffle': True,\n",
    "              'num_workers': 8,\n",
    "              'drop_last': True}\n",
    "\n",
    "# Using Dataset class\n",
    "class Dataset(data.Dataset):\n",
    "    def __init__(self, features, targets):\n",
    "    # Initialise data to be used by the other functions\n",
    "        self.features = features\n",
    "        self.targets = targets\n",
    "    \n",
    "    def __len__(self):\n",
    "    # Length of the dataset, i.e. number of samples\n",
    "        return len(self.targets)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "    # Returns sample from the dataset\n",
    "        x = torch.FloatTensor(self.features[index])\n",
    "        y = self.targets[index]\n",
    "        \n",
    "        return x, y\n",
    "    \n",
    "# Apply generators to the data\n",
    "training_set = Dataset(x_train, targets_train)\n",
    "training_generator = data.DataLoader(training_set, **params)\n",
    "\n",
    "validation_set = Dataset(x_valid, targets_valid)\n",
    "validation_generator = data.DataLoader(validation_set, **params)\n",
    "\n",
    "test_set = Dataset(x_test, targets_test)\n",
    "test_generator = data.DataLoader(test_set, **params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model\n",
    "\n",
    "We have the following parameters:\n",
    "\n",
    "- $ n $: number of outputs\n",
    "- $ p $: dimension of vandermonde vectors\n",
    "- $ D $: rank of decomposed tensor\n",
    "\n",
    "We want to do the function contraction\n",
    "\n",
    "$ f = \\sum_i^D \\textbf{U}_i  \\, \\in \\mathbb{R}^n $\n",
    "\n",
    "Where:\n",
    "\n",
    "$ \\textbf{U} = \\textbf{M}_1 \\odot \\textbf{M}_2 \\odot ... \\odot \\textbf{M}_d  \\, \\in \\mathbb{R}^{D \\times n} $\n",
    "\n",
    "$ \\odot $ is the elementwise vector multiplication and\n",
    "\n",
    "$ \\textbf{M}_i = (\\textbf{v}^{(i)})^T \\mathcal{A}_i^{p \\times D \\times n}\n",
    "    \\, \\in \\mathbb{R}^{D \\times n} $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Number of output classes\n",
    "num_classes = 10\n",
    "\n",
    "# define network\n",
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self, num_features, poly_order, num_output, rank):\n",
    "        super(Net, self).__init__()  \n",
    "        \n",
    "        # weight tensors collected in one tensor\n",
    "        tn_size = tuple([num_features] + [poly_order] + [rank] + [num_output]) # size of all tensors A_i\n",
    "        self.A = Parameter(init.normal_(torch.empty(tn_size, requires_grad=True), std=0.575))\n",
    "\n",
    "    def forward(self, vec_input, batch_size, print_expr=False):\n",
    "        \n",
    "        m = torch.einsum('abcd,eab->aced',self.A ,vec_input)\n",
    "        f = torch.prod(m,0)\n",
    "        \n",
    "        return torch.sum(f,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net(num_features, poly_order, num_classes, rank).to(device)\n",
    "\n",
    "optimizer = optim.Adam(net.parameters())\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1 : Train Loss 0.575645 , Train acc 0.138672, Valid acc 0.119141\n",
      "CUDA memory usage in Gb:  3.584e-05\n",
      "Norm G's tensor(26.6752, device='cuda:0', grad_fn=<NormBackward0>)\n",
      "Epoch 11 : Train Loss 0.575169 , Train acc 0.184570, Valid acc 0.187500\n",
      "CUDA memory usage in Gb:  4.096e-05\n",
      "Norm G's tensor(28.1780, device='cuda:0', grad_fn=<NormBackward0>)\n",
      "Epoch 21 : Train Loss 0.542227 , Train acc 0.207031, Valid acc 0.214844\n",
      "CUDA memory usage in Gb:  4.6080000000000006e-05\n",
      "Norm G's tensor(32.3354, device='cuda:0', grad_fn=<NormBackward0>)\n",
      "Epoch 31 : Train Loss 0.526144 , Train acc 0.217773, Valid acc 0.232422\n",
      "CUDA memory usage in Gb:  5.1200000000000004e-05\n",
      "Norm G's tensor(34.5144, device='cuda:0', grad_fn=<NormBackward0>)\n",
      "Epoch 41 : Train Loss 0.518911 , Train acc 0.232422, Valid acc 0.236328\n",
      "CUDA memory usage in Gb:  5.632e-05\n",
      "Norm G's tensor(35.8878, device='cuda:0', grad_fn=<NormBackward0>)\n",
      "Epoch 51 : Train Loss 0.512537 , Train acc 0.239258, Valid acc 0.246094\n",
      "CUDA memory usage in Gb:  6.144000000000001e-05\n",
      "Norm G's tensor(37.1930, device='cuda:0', grad_fn=<NormBackward0>)\n",
      "Epoch 61 : Train Loss 0.507232 , Train acc 0.243164, Valid acc 0.240234\n",
      "CUDA memory usage in Gb:  6.656e-05\n",
      "Norm G's tensor(38.2117, device='cuda:0', grad_fn=<NormBackward0>)\n",
      "Epoch 71 : Train Loss 0.504136 , Train acc 0.243164, Valid acc 0.251953\n",
      "CUDA memory usage in Gb:  7.168e-05\n",
      "Norm G's tensor(38.8247, device='cuda:0', grad_fn=<NormBackward0>)\n",
      "Epoch 81 : Train Loss 0.501088 , Train acc 0.247070, Valid acc 0.246094\n",
      "CUDA memory usage in Gb:  7.680000000000001e-05\n",
      "Norm G's tensor(39.2758, device='cuda:0', grad_fn=<NormBackward0>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-d506668538c5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;31m### Evaluate validation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0mval_preds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_targs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalidation_generator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/virtualenv/LSM/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    277\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0m_SingleProcessDataLoaderIter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 279\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0m_MultiProcessingDataLoaderIter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/virtualenv/LSM/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, loader)\u001b[0m\n\u001b[1;32m    717\u001b[0m             \u001b[0;31m#     before it starts, and __del__ tries to join but will get:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m             \u001b[0;31m#     AssertionError: can only join a started process.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 719\u001b[0;31m             \u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    720\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_index_queues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex_queue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_workers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/appl/python/3.6.2/lib/python3.6/multiprocessing/process.py\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    103\u001b[0m                \u001b[0;34m'daemonic processes are not allowed to have children'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0m_cleanup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_popen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_Popen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sentinel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_popen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentinel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0m_children\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/appl/python/3.6.2/lib/python3.6/multiprocessing/context.py\u001b[0m in \u001b[0;36m_Popen\u001b[0;34m(process_obj)\u001b[0m\n\u001b[1;32m    221\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_Popen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_default_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mProcess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_Popen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mDefaultContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseContext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/appl/python/3.6.2/lib/python3.6/multiprocessing/context.py\u001b[0m in \u001b[0;36m_Popen\u001b[0;34m(process_obj)\u001b[0m\n\u001b[1;32m    275\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m_Popen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m             \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mpopen_fork\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPopen\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mPopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m     \u001b[0;32mclass\u001b[0m \u001b[0mSpawnProcess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBaseProcess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/appl/python/3.6.2/lib/python3.6/multiprocessing/popen_fork.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_launch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mduplicate_for_child\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/appl/python/3.6.2/lib/python3.6/multiprocessing/popen_fork.py\u001b[0m in \u001b[0;36m_launch\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0mcode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0mparent_r\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchild_w\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpipe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpid\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Training the model\n",
    "# we could have done this ourselves,\n",
    "# but we should be aware of sklearn and it's tools\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# setting hyperparameters and gettings epoch sizes\n",
    "#batch_size = 64 this is set by the generators\n",
    "num_epochs = 1000\n",
    "\n",
    "#if run_as_dist:\n",
    "#    dist.init_process_group(\"gloo\", rank=rank, world_size=size)\n",
    "\n",
    "# setting up lists for handling loss/accuracy\n",
    "train_acc, train_loss = [], []\n",
    "valid_acc, valid_loss = [], []\n",
    "test_acc, test_loss = [], []\n",
    "cur_loss = 0\n",
    "losses = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Forward -> Backprob -> Update params\n",
    "    ## Train\n",
    "    net.train()\n",
    "    cur_loss = 0\n",
    "    count = 0\n",
    "    for data, labels in training_generator:\n",
    "        count += 1\n",
    "        # Transfer training data and targets to device\n",
    "        data = data.to(device)\n",
    "        target_batch = Variable(labels.long()).to(device)\n",
    "        \n",
    "        # Send it through the model\n",
    "        output = net(data, batch_size)\n",
    "          \n",
    "        # compute gradients given loss\n",
    "        batch_loss = criterion(output, target_batch)\n",
    "        optimizer.zero_grad()\n",
    "        batch_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        #if count % 25 == 0:\n",
    "        #    print(next(net.parameters()))\n",
    "        \n",
    "        cur_loss += batch_loss   \n",
    "        \n",
    "        # Manually release memory\n",
    "        try:\n",
    "            del data, labels, target_batch, output, batch_loss \n",
    "            torch.cuda.empty_cache()\n",
    "        except:\n",
    "            print(\"Memory not released in training.\")\n",
    "       \n",
    "    losses.append(cur_loss / batch_size)\n",
    "\n",
    "    net.eval()\n",
    "    ### Evaluate training\n",
    "    train_preds, train_targs = [], []\n",
    "    for data, labels in training_generator:\n",
    "        data = data.to(device)\n",
    "        \n",
    "        output = net(data, batch_size)\n",
    "        preds = torch.max(output, 1)[1]\n",
    "        \n",
    "        train_targs += list(labels)\n",
    "        train_preds += list(preds.data.cpu().numpy())\n",
    "        \n",
    "        # Manually release memory\n",
    "        try:\n",
    "            del data, labels, output, preds \n",
    "            torch.cuda.empty_cache()\n",
    "        except:\n",
    "            print(\"Memory not released in training evaluation.\")\n",
    "    \n",
    "    ### Evaluate validation\n",
    "    val_preds, val_targs = [], []\n",
    "    for data, labels in validation_generator:\n",
    "        data = data.to(device)\n",
    "        \n",
    "        output = net(data, batch_size)\n",
    "        preds = torch.max(output, 1)[1]\n",
    "        val_preds += list(preds.data.cpu().numpy())\n",
    "        val_targs += list(labels)\n",
    "        \n",
    "        # Manually release memory\n",
    "        try:\n",
    "            del data, labels, output, preds\n",
    "            torch.cuda.empty_cache()\n",
    "        except:\n",
    "            print(\"Memory not released in validation.\")\n",
    "        \n",
    "    train_acc_cur = accuracy_score(train_targs, train_preds)\n",
    "    valid_acc_cur = accuracy_score(val_targs, val_preds)\n",
    "    \n",
    "    train_acc.append(train_acc_cur)\n",
    "    valid_acc.append(valid_acc_cur)\n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "        print(\"Epoch %2i : Train Loss %f , Train acc %f, Valid acc %f\" % (\n",
    "                epoch+1, losses[-1], train_acc_cur, valid_acc_cur))\n",
    "        print(\"CUDA memory usage in Gb: \",torch.cuda.memory_allocated()*1000**(-3))\n",
    "        print('Norm G\\'s',torch.norm(next(net.parameters()),p='fro'))\n",
    "        #print(next(net.parameters()))\n",
    "        \n",
    "#if run_as_dist:\n",
    "#    dist.reduce(x, dst=0)\n",
    "        \n",
    "epoch = np.arange(len(train_acc))\n",
    "plt.figure()\n",
    "plt.plot(epoch, train_acc, 'r', epoch, valid_acc, 'b')\n",
    "plt.legend(['Train Accucary','Validation Accuracy'])\n",
    "plt.xlabel('Updates'), plt.ylabel('Acc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[[[ 3.3556e-02, -8.2192e-01, -9.1985e-01,  ..., -1.6071e-01,\n",
      "            4.7410e-01,  7.9224e-01],\n",
      "          [-8.8718e-01,  1.2570e+00,  1.7975e-01,  ...,  9.0794e-01,\n",
      "           -1.0174e+00, -2.3983e+00],\n",
      "          [ 6.2381e-01,  3.9675e-02, -9.3445e-01,  ...,  1.3172e+00,\n",
      "            6.4101e-01,  1.0568e+00],\n",
      "          ...,\n",
      "          [ 1.6745e+00, -1.4628e+00, -8.0604e-01,  ..., -1.4626e+00,\n",
      "           -5.5019e-01,  1.5910e+00],\n",
      "          [ 2.4761e+00,  1.6407e-01, -1.3961e-01,  ..., -6.8486e-01,\n",
      "            1.7981e-01,  1.2158e+00],\n",
      "          [ 2.6932e-01,  1.2528e+00,  1.0200e+00,  ...,  2.3375e-02,\n",
      "           -7.0846e-01, -3.7548e-01]],\n",
      "\n",
      "         [[ 9.3180e-01,  6.3440e-01, -1.8776e-01,  ..., -9.3470e-01,\n",
      "           -3.4082e-01, -3.5804e-01],\n",
      "          [-1.8652e+00, -6.1778e-01, -9.5931e-01,  ...,  2.9813e-01,\n",
      "            8.2676e-01, -5.9309e-01],\n",
      "          [ 1.9158e+00, -3.5770e-01, -1.3111e+00,  ...,  1.1865e-01,\n",
      "            1.7118e-02,  1.8258e-03],\n",
      "          ...,\n",
      "          [-9.2983e-01, -6.8663e-01, -1.4789e-01,  ..., -9.1496e-01,\n",
      "           -7.8224e-01, -4.3815e-01],\n",
      "          [-5.6609e-01, -9.1297e-01,  2.3421e-01,  ...,  6.1907e-01,\n",
      "           -1.2719e-01, -1.5741e-01],\n",
      "          [ 1.0289e+00,  9.1153e-02,  1.6708e-02,  ..., -5.2960e-01,\n",
      "           -8.0468e-01, -5.0159e-01]]],\n",
      "\n",
      "\n",
      "        [[[-3.3040e-02,  1.3009e+00, -9.0200e-01,  ..., -5.1313e-01,\n",
      "            3.8756e-01,  9.8686e-01],\n",
      "          [ 9.0184e-01, -1.3053e+00, -2.8225e-01,  ...,  1.3528e+00,\n",
      "            7.0013e-01,  6.1083e-01],\n",
      "          [-1.1081e+00,  6.0394e-01,  1.1074e+00,  ...,  1.1682e+00,\n",
      "            7.9643e-01, -9.6984e-01],\n",
      "          ...,\n",
      "          [ 8.9124e-01, -8.8774e-01, -1.2426e+00,  ..., -1.1633e+00,\n",
      "            1.4948e-01,  7.4347e-01],\n",
      "          [ 1.0503e+00,  8.6731e-01, -4.1415e-01,  ...,  1.4687e+00,\n",
      "           -4.6528e-01,  7.0589e-01],\n",
      "          [-6.6819e-01, -1.5604e+00, -1.3264e+00,  ...,  1.5956e-01,\n",
      "           -3.3384e-01,  1.8347e-01]],\n",
      "\n",
      "         [[ 4.3748e-01, -5.4967e-01,  3.2084e-01,  ..., -6.6739e-02,\n",
      "            5.8845e-01, -5.7035e-01],\n",
      "          [ 9.3960e-01,  2.9662e-01, -2.4187e-01,  ..., -4.4630e-01,\n",
      "           -7.5681e-01,  5.0828e-01],\n",
      "          [-5.2957e-01,  9.8220e-02,  4.6873e-01,  ...,  1.6727e+00,\n",
      "            7.9261e-01,  3.3113e-01],\n",
      "          ...,\n",
      "          [-5.2262e-02, -1.1358e+00, -3.1660e-01,  ...,  2.1102e-01,\n",
      "           -8.1895e-01,  5.6396e-01],\n",
      "          [ 1.2361e+00,  8.4126e-01,  5.4427e-01,  ..., -1.3144e+00,\n",
      "            1.2386e-01,  4.2042e-01],\n",
      "          [ 5.3081e-01,  7.1820e-01, -9.2413e-01,  ...,  4.4470e-02,\n",
      "           -1.1141e+00, -2.1063e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.1184e-01, -8.7193e-01,  1.3067e+00,  ...,  3.6920e-01,\n",
      "           -3.9584e-01,  1.3173e+00],\n",
      "          [ 9.6016e-01, -1.0527e+00,  8.7537e-01,  ..., -7.2998e-01,\n",
      "           -1.6778e+00, -8.4522e-01],\n",
      "          [ 7.0915e-01,  8.1883e-02,  9.6600e-01,  ..., -1.4868e+00,\n",
      "            1.1594e+00,  1.1438e+00],\n",
      "          ...,\n",
      "          [ 6.0510e-01, -1.2391e+00,  1.4280e+00,  ..., -1.2207e+00,\n",
      "           -5.0010e-01, -8.9259e-01],\n",
      "          [ 1.1911e+00,  6.4403e-01, -4.6451e-01,  ..., -1.1985e+00,\n",
      "            5.0160e-02,  8.6085e-01],\n",
      "          [ 4.4902e-01, -2.6008e-01, -1.1608e+00,  ..., -1.2293e-01,\n",
      "            1.0249e+00, -2.9090e-01]],\n",
      "\n",
      "         [[-7.9261e-01,  1.5380e-01,  4.3630e-02,  ...,  4.2204e-01,\n",
      "           -6.0146e-01,  7.9145e-01],\n",
      "          [-2.0850e-01,  3.1856e-01,  1.3749e-01,  ...,  1.1576e+00,\n",
      "            9.6988e-02, -1.5209e+00],\n",
      "          [ 9.7033e-01,  3.6958e-01,  1.5858e+00,  ...,  1.3456e-01,\n",
      "            6.1808e-01, -2.7484e-02],\n",
      "          ...,\n",
      "          [-7.7934e-01, -5.1195e-01,  1.7111e+00,  ..., -2.3124e-01,\n",
      "            4.8065e-01,  8.2178e-01],\n",
      "          [-4.4324e-02, -1.0037e-01,  1.1018e-01,  ...,  1.2810e+00,\n",
      "           -3.1413e-01,  5.9444e-01],\n",
      "          [ 6.8325e-01,  2.0024e+00, -4.3706e-01,  ..., -9.3326e-02,\n",
      "            1.1471e+00,  6.4555e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-1.6748e-02, -6.7952e-01, -7.5182e-01,  ..., -1.2473e-02,\n",
      "           -1.0253e+00,  1.5365e+00],\n",
      "          [-1.7030e-02,  7.7991e-01,  7.3339e-03,  ...,  1.2313e+00,\n",
      "            7.4499e-01, -1.6042e+00],\n",
      "          [-7.8737e-01, -1.4044e+00, -1.1485e+00,  ..., -1.4260e+00,\n",
      "            5.8074e-01,  1.7327e+00],\n",
      "          ...,\n",
      "          [-1.4734e+00, -1.3458e+00, -9.3500e-01,  ...,  1.3671e+00,\n",
      "            7.8332e-02, -1.0665e+00],\n",
      "          [ 1.9950e+00,  1.1264e+00, -9.8554e-01,  ..., -1.2614e+00,\n",
      "           -7.6999e-01,  6.9309e-01],\n",
      "          [-7.2012e-01, -1.0337e+00,  3.1832e-01,  ...,  8.8665e-01,\n",
      "            7.1435e-01, -9.7694e-01]],\n",
      "\n",
      "         [[-4.3575e-02,  1.9920e+00, -8.4142e-01,  ..., -4.3937e-01,\n",
      "           -8.4362e-01, -7.4881e-01],\n",
      "          [ 6.5377e-01, -2.3994e+00, -1.3993e-02,  ...,  1.6962e-01,\n",
      "           -8.9177e-01, -6.6332e-01],\n",
      "          [-1.2977e+00,  8.3412e-01, -1.0117e+00,  ..., -1.6966e+00,\n",
      "            7.6463e-01,  6.9283e-01],\n",
      "          ...,\n",
      "          [ 6.2703e-01, -1.1271e+00,  2.8430e-01,  ...,  2.3796e-01,\n",
      "            2.9158e-01, -8.9917e-01],\n",
      "          [ 5.7757e-02,  1.7870e-01,  1.8094e-01,  ...,  5.0031e-01,\n",
      "            2.1439e+00,  1.3944e+00],\n",
      "          [-8.1917e-01,  6.3436e-02,  1.8724e+00,  ...,  4.1374e-01,\n",
      "           -4.1370e-01,  6.7312e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 6.8509e-02, -1.5186e+00, -7.7773e-01,  ...,  2.1021e-01,\n",
      "           -2.1787e-01,  1.1098e+00],\n",
      "          [-7.4104e-01,  7.9799e-01, -6.1967e-01,  ..., -7.0988e-01,\n",
      "           -7.0379e-01,  1.3554e+00],\n",
      "          [-1.0939e+00, -8.3764e-01, -6.1171e-01,  ...,  1.2722e+00,\n",
      "            1.2921e+00,  5.6112e-01],\n",
      "          ...,\n",
      "          [ 3.6964e-01,  7.8375e-01, -8.8551e-01,  ..., -1.2933e+00,\n",
      "           -2.2475e-01, -2.4849e-01],\n",
      "          [-7.0839e-01,  3.1480e-01, -7.5322e-01,  ..., -1.7399e+00,\n",
      "           -1.2950e+00, -4.3632e-01],\n",
      "          [-7.3441e-03,  3.1303e-01,  1.1508e+00,  ...,  8.7364e-01,\n",
      "           -7.9570e-01,  1.0633e-01]],\n",
      "\n",
      "         [[-8.1582e-02,  8.4222e-01, -7.0891e-01,  ..., -4.6296e-01,\n",
      "            2.0775e-01,  2.9675e-01],\n",
      "          [-3.0718e-01, -2.4386e-01,  4.7856e-01,  ..., -8.9136e-01,\n",
      "           -3.0049e-01,  2.1312e-01],\n",
      "          [ 1.9190e-01,  4.7146e-01,  7.9246e-01,  ...,  7.7695e-03,\n",
      "            7.9988e-01,  4.7700e-01],\n",
      "          ...,\n",
      "          [ 1.5395e+00,  2.3795e-01, -1.8368e-02,  ...,  7.4054e-01,\n",
      "           -2.8443e-01, -9.5528e-01],\n",
      "          [-3.6281e-01, -2.9235e-01, -3.2870e-01,  ..., -6.5032e-01,\n",
      "           -4.3926e-01,  1.1563e+00],\n",
      "          [-5.7651e-01, -9.4827e-01, -1.0243e+00,  ..., -6.5695e-01,\n",
      "            1.5141e-01,  4.6220e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 3.0250e-01, -8.1189e-01,  1.3880e+00,  ..., -9.1278e-03,\n",
      "           -4.0604e-01, -8.3462e-01],\n",
      "          [ 8.0978e-01,  9.8247e-01,  3.8733e-01,  ..., -9.7359e-01,\n",
      "           -8.3489e-01,  7.9435e-01],\n",
      "          [-2.3630e-01,  3.1154e-01, -4.9984e-01,  ..., -9.6774e-01,\n",
      "            5.4247e-01,  8.0152e-01],\n",
      "          ...,\n",
      "          [-1.3055e+00,  1.0064e+00, -1.4165e+00,  ...,  1.1561e+00,\n",
      "           -1.9845e-01, -8.6371e-01],\n",
      "          [-9.4687e-01,  2.5775e-01,  1.4964e-01,  ..., -1.2225e+00,\n",
      "            1.1605e+00,  6.8859e-01],\n",
      "          [ 6.3428e-01,  1.3303e+00,  8.8308e-01,  ...,  5.3072e-01,\n",
      "           -5.8813e-01, -2.8578e-01]],\n",
      "\n",
      "         [[-2.7979e-01,  1.1842e+00,  4.0464e-01,  ..., -2.3370e-01,\n",
      "            3.8286e-01,  7.3341e-01],\n",
      "          [ 3.5603e-02, -1.2322e+00, -4.4455e-01,  ..., -8.0159e-01,\n",
      "           -1.2842e+00,  9.5464e-01],\n",
      "          [-1.8679e+00,  6.4453e-02, -6.3409e-01,  ..., -2.8878e-01,\n",
      "            5.1576e-01,  1.2757e+00],\n",
      "          ...,\n",
      "          [-2.0982e-01,  8.3920e-01,  1.8567e-01,  ..., -1.1246e-02,\n",
      "           -3.8015e-01, -4.2971e-01],\n",
      "          [-4.1435e-01,  6.2605e-01,  2.5629e-01,  ..., -1.3703e+00,\n",
      "            4.2688e-01,  2.0737e-01],\n",
      "          [ 2.2322e-01,  8.0778e-01,  1.7465e+00,  ..., -2.8993e-01,\n",
      "           -1.8844e-01, -3.0009e-01]]]], device='cuda:0', requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for G in net.parameters():\n",
    "    print(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
